{"name":"Reconocimiento de Dígitos en Castellano utilizando HTK","tagline":"htk, reconocimiento de dígitos, español, castellano, speech-recognition, machine learning","body":"# Bienvenidos\r\nA continuación implementaremos un reconocedor de dígitos en español, más precisamente el español hablado en Argentina. Para ello utilizaremos HTK (una implementación de [Modelos Ocultos de Markov](http://es.wikipedia.org/wiki/Modelo_oculto_de_Márkov)) y seguiremos los pasos recomendados en el [manual de HTK](http://htk.eng.cam.ac.uk/docs/docs.shtml).\r\n\r\nLa idea de este tutorial es que contenga todas las herramientas necesarias para implementar **desde cero** un programa que reconozca los números del 0 al 9. \r\n\r\nPueden ver el código completo en este [repositorio.](https://bitbucket.org/pbrusco/tesis-proyectos/src/e393a5db8f242bb9b173f570fdd06554be5aa968/HTK/spike%20digitos?at=master)\r\n\r\n### Hacia dónde vamos?\r\nQueremos, a partir de grabaciones de entrada de la pinta:\r\n\r\n**Entrada**\r\n ![12151516790](https://dl.dropboxusercontent.com/u/43547597/Tutorial%20HTK/12151516790.png)\r\n                \r\nobtener la transcripción de los dígitos, por ejemplo\r\n\r\n**Salida**\r\n\"1 2 1 5 1 5 1 6 7 9 0\"\r\n\r\n##Preámbulos\r\nLa tarea de reconocimiento del habla (speech recognition) es una tarea difícil. La mayor dificultad está en la enorme cantidad de variaciones al analizar una palabra dicha por dos personas distintas, a través de dos canales distintos (estudio radial vs. teléfono), en situaciones distintas, con distintas emociones, por dos personas que hablan el mismo idioma pero de distintos orígenes, etc. E incluso, una misma persona intentando reproducir lo que dijo, nunca puede hacerlo exactamente igual. \r\n\r\nEsto implica, que la tarea de hacer que una maquina reconozca el habla incluye facilitarle datos de entrenamiento suficientes y buenos algoritmos para normalizar la señal acústica. \r\n\r\nAlgunos de los métodos más utilizados en los últimos años están basados en \"Hidden Markov Models\" (HMMs), modelos formales probabilísticos que hablan sobre probabilidades de, por ejemplo, que cierto fonema sea dicho de una u otra manera, o que luego de cierta parte de un fonema continúe alguna otra parte, etc.\r\nLuego, se combina esta técnica con otras como una que permite normalizar las señales sonoras extrayendo su esencia, una de las técnicas más utilizadas es la que consta de extraer los llamados [Mel Frecuency Ceptral Coefficients (MFCCs)](http://es.wikipedia.org/wiki/MFCC) y luego, por ejemplo, utilizando [Gaussian Mixture Models (GMMs)](http://en.wikipedia.org/wiki/Mixture_model#Gaussian_mixture_model), se consigue finalmente que se pueda comparar palabras habladas a pesar de sus variaciones esperables. \r\n\r\nExisten varios sistemas (o toolkits) que implementan y facilitan la interacción y entrenamiento de HMMs. En este tutorial utilizaremos [The Hidden Markov Model Toolkit (HTK)](http://htk.eng.cam.ac.uk). \r\n\r\n##Preparando el entorno\r\n\r\n###Software\r\nLa forma de instalar el software necesario depende de nuestro sistema operativo, aquí mostraremos como lograrlo en Ubuntu y Mac OS X.\r\n\r\n\r\nPara poder generar nuestro reconocedor, primero debemos descargar [HTK](http://htk.eng.cam.ac.uk/download.shtml), luego, dentro de la carpeta descargada: \r\n\r\n```\r\n ./configure\r\nmake all\r\nsudo make install\r\n```\r\n\r\n**HTK en Ubuntu**\r\n\r\nAnte algún problema, ejecutar:\r\n\r\n```\r\nsudo apt-get install gcc-multilib\r\nsudo apt-get install libx11-dev\r\n./configure --disable-hslab (por un error -lX11) \r\nsudo apt-get install libc6-dev-i386 \r\nsudo apt-get install libx11-dev:i386\r\n\r\n```\r\n(si fue necesario realizar el ultimo paso, no dispondremos de la herramienta HSLab, reemplazable por, por ejemplo, audacity)\r\n\r\n**HTK en MAC (Mountain Lion)**\r\n\r\nAnte algún problema, asegurarse de tener instalado:\r\n\r\n* [XQuartz](http://xquartz.macosforge.org/landing/) (del cual necesitamos X11)\r\n* gcc, disponible con los [Command Line Tools](http://www.programadorfreelanceargentina.com/2012/05/como-instalar-xcode-command-line-tools.html) de XCode \r\n\r\nSi el problema persiste, agregar `-I/usr/X11R6/include` en los cflags de los makefiles que estan, en el directorio de htk y en htklib, (información sacada de esta [página] (http://aidiary.hatenablog.com/entry/20130113/1358046622), para leerla, traducir usando el traductor de google por ejemplo y tener cuidado que los comandos también se traducen). \r\n\r\n\r\n**Ruby**\r\n\r\nAdemás de HTK, recomiendo tener instalado [Ruby](http://www.ruby-lang.org/es/downloads/) (para ciertos scripts .rb) y [RubyGems](http://rubygems.org/pages/download)\r\n\r\n**Aclaración importante** Todos los scripts hechos en ruby, son simplemente automatizaciones de procesos que se pueden hacer tranquilamente a mano e incluso, la mayoría necesitan de un simple editor de texto. Recomiendo intentar realizar a mano el proceso antes (o incluso después) de correr los .irb para entender que funcionalidad aplican.\r\n\r\n###Organización del código\r\nPara lograr hacer funcionar el programa, deberemos fijar la ubicación de cada uno de los archivos que creemos, recomiendo utilizar la misma estructura que yo utilizo ya que los comandos están preparados para estas rutas. Por supuesto, al ir entendiendo cada uno de los comandos y scripts, los archivos podrán ser movidos a donde el que los utilice considere.\r\n\r\n[Aquí](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/code_organization.txt?at=master) podrán encontrar una posible organización y es en la cual me basaré a partir de ahora. La idea no es intentar entenderla desde un principio, sino consultarla cuando se tiene alguna duda. \r\n\r\nLes dejo también un script para crear la estructura troncal en cualquier sistema con Unix que contiene los scripts de ruby que utilizaremos [crear_estructura.bash](https://gist.github.com/pbrusco/5389168) y luego llenar la carpeta Helpers con los estos [archivos](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Helpers?at=master). La forma de correrlo es, copiando el contenido del archivo en una consola, o, al bajar el archivo, ejecutar `./crear_estructura.bash`.\r\n\r\nRecomiendo también, utilizar un buen sistema de control de versiones (git, hg, svn, etc) para hacer commits ante cada paso logrado y así estar más preparados ante un olvido o un error en el proceso. \r\n\r\nListo, con la estructura creada, podemos empezar a trabajar en nuestro reconocedor.\r\n\r\n###Sobre el formato de los archivos\r\nUna aclaración que puede ahorrarles horas de errores incomprensibles. En **TODOS** los archivos que se utilicen en los comandos de HTK, chequeen que siempre haya un \"enter\" al final (y que se encuentre en formato unix, opción disponible si usan [Sublime](http://www.sublimetext.com/) en View - Line Endings - Unix por ejemplo)\r\n\r\n\r\n# Implementación\r\n##Idea general\r\nLa implementación de este reconocedor constará de 4 pasos esenciales:\r\n- Preparación de datos\r\n- Combinación de datos\r\n- Entrenamiento del modelo\r\n- Generación de resultados\r\n\r\nEn los primeros dos pasos, generaremos los archivos necesarios para definir que tipo y de que manera reconoceremos palabras en el sistema (gramática, diccionario, listados de palabras). Luego, grabaremos el audio necesario para el entrenamiento y lo convertiremos a un formato aceptable para los modelos (de .wav a MFCCs) mientras preparamos un modelo prototipo que utilizaremos en los siguientes pasos.\r\n\r\nEn el tercer paso, nos concentraremos en entrenar y pulir los modelos que van a servir para reconocer las grabaciones de prueba, es decir, entrenar los HMMs puliendo las distribuciones probabilísticas asociadas a los distintos estados. \r\n\r\nFinalmente, en el cuarto paso, grabaremos datos de prueba y los utilizaremos para ver que tan buena fue nuestra aproximación a lo que uno espera de un reconocedor de palabras.\r\n\r\n\r\n##1. Preparando los datos\r\nEn esta sección generaremos la gramática, los listados y el diccionario base para comenzar a trabajar. Por otro lado, debemos conseguir (o grabar) los archivos de audio que usaremos para entrenar al sistema. \r\n\r\n###1.1. Gramática\r\nPara que nuestro programa entienda palabras, lo primero que debemos indicarle es que forma pueden tener las oraciones que grabemos.\r\n\r\nDado que en nuestro caso queremos reconocer dígitos, lo haremos con la siguiente grámatica:\r\n```\r\n$digito = UNO | DOS | TRES | CUATRO | CINCO | SEIS | SIETE | OCHO | NUEVE | CERO;\r\n( SENT-START ( <$digito> ) SENT-END )\r\n```\r\nNombre del archivo: [Dictionary/DictionarySources/grammar](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/DictionarySources/grammar?at=master)\r\n\r\nMás info sobre el [lenguaje utilizado](http://www.ee.columbia.edu/ln/LabROSA/doc/HTKBook21/node131.html)\r\n\r\nBásicamente, se indica a través de este archivo, que las grabaciones tendrán dígitos (uno o más). \r\n\r\n###1.2. Listado de palabras\r\nEn este paso debemos listar todas las posibles palabras de nuestra gramática (ordenadas alfabeticamente). Para ello, podemos listarlas y luego aplicar el comando \"sort\" de unix. \r\n```\r\nCERO\r\nCINCO\r\nCUATRO\r\nDOS\r\nNUEVE\r\nOCHO\r\nSEIS\r\nSIETE\r\nTRES\r\nUNO\r\n```\r\nNombre del archivo: [Dictionary/DictionarySources/words-sorted.list](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/DictionarySources/words-sorted.list?at=master)\r\n\r\n###1.3. Diccionario de fonemas\r\nEste paso es importante e indica que fonemas utilizaremos para describir cada palabra, aquí es donde, el español hablado en España varía del hablado en Argentina, por ejemplo, la palabra \"cero\" puede tener las siguientes transcripciones a fonemas respectivamente.\r\n`CERO th e r o` o `CERO s e r o`\r\n\r\nPor lo tanto, el diccionario tendrá la siguiente pinta:\r\n\r\n```\r\nCERO s e r o sp\r\nCINCO s i n c o sp\r\nCUATRO k u a t r o sp\r\nDOS d o s sp\r\nNUEVE n u e b e sp\r\nOCHO o ch o sp\r\nSEIS s e i s sp\r\nSIETE s i e t e sp\r\nTRES t r e s sp\r\nUNO u n o sp\r\n```\r\nNombre del archivo: [Dictionary/DictionarySources/dict](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/DictionarySources/dict?at=master)\r\n\r\n\r\n###1.4. Grabando datos de entrenamiento\r\nPara poder entrenar nuestro sistema, se necesitan grabaciones de entrenamiento, la decisión sobre que datos de entrenamiento usar implican un mejor o peor desempeño en el reconocedor. Para esta prueba en particular, se grabaron 4 sets de entrenamiento (train1, train2, train3 y train4) en dónde cada uno contiene una grabación por cada dígito (de manera aislada, es decir, solo el dígito de comienzo a fin sin silencios). \r\n\r\nEjemplo: [Data/Recorded/waves/train/train1/seis.wav](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/Recorded/waves/train/train1/seis.wav?at=master)\r\n\r\nPara lograr compatibilidad con HTK, usaremos el siguiente formato para grabar (entre paréntesis indico donde encontrar la opción si utilizamos Audacity 2.0.3):\r\n- Mono (Edit\\Preferences\\Devices) \r\n- 16 kHz sampling frequency (Edit\\Preferences\\Quality\\Sampling) \r\n- 16 bits por sample (Edit\\Preferences\\Quality\\Sampling) \r\n    \r\n\r\nPor otro lado, cada uno de estos datos de entrenamiento necesitan una transcripción (.lab), esta transcripción debe contener los fonemas que se utilizan en la palabra grabada. \r\n\r\nEn vez de hacerlo manualmente, aprovecharemos un script que se encargará de facilitarnos ese trabajo, pero en caso de no tener este script, habría que construirlos manualmente con la pinta:\r\n\r\n```\r\n0.0 0.5064375  o ch o\r\n```\r\nNombre del archivo: [Data/Train/train1-ocho.lab](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/Train/train1-ocho.lab?at=master)\r\n\r\nEl script que utilizaremos es [Helpers/labels_from_wavs_script.rb](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Helpers/labels_from_wavs_script.rb?at=master)\r\n\r\n```\r\nsudo gem install waveinfo\r\nirb Helpers/labels_from_wavs_script.rb \"Data/Recorded/waves/train/\" \"Data/Train/\"\r\n```\r\n\r\nEste script escanea la carpeta de origen (Data/Recorded/waves/train) en búsqueda de subcarpetas que contengan wavs. Al encontrarlos, genera un archivo .lab por cada .wav (si no existe previamente en la carpeta de origen) y los guarda en el la carpeta de destino (segundo parametro) \"Data/Train/\" con el nombre \"subcarpeta\"-\"nombre\".lab (ejemplo el archivo train1-ocho.lab mostrado anteriormente).\r\nSi existía un .lab en alguna de las subcarpetas del origen (ver [train5](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/Recorded/waves/train/train5?at=master) por ejemplo) el script copia estas transcripciones agregándoles en el nombre, el prefijo de la subcarpeta correspondiente. Se puede ver un ejemplo de este caso en [Data/Train/train5-siete](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/Train/train5-siete.lab?at=master), notar que el .lab no fue generado automaticamente sino copiado de la carpeta train5. \r\n\r\n\r\n\r\n##2. Combinando los datos\r\nEn esta sección, nos concentraremos en dejar todo listo para empezar con el entrenamiento. Generaremos un diccionario y listado de fonemas, convertiremos la gramática a un formato estándar, crearemos Master Label Files, convertiremos el audio a su vector de features (MFCCs), y crearemos las carpetas necesarias para almacenar los distintos modelos que irán avanzando a medida que avance el entrenamiento. \r\n\r\n###2.1. Diccionario y listado de fonemas\r\n\r\nPara generar el diccionario y listado de fonemas que utilizaremos más adelante, usaremos el comando HDMan de HTK: \r\n\r\n```\r\nHDMan -m -w Dictionary/DictionarySources/words-sorted.list -n Dictionary/phones-with-sp.list -l dlog Dictionary/phones.dict Dictionary/DictionarySources/dict\r\n```\r\n\r\nEsto último, genera 2 archivos importantes: Dictionary/phones.dict y Dictionary/phones-with-sp.list, y por otro lado, un log (dlog) que sirve para ver cuantas repeticiones de los fonemas se utilizan. \r\n\r\nLo que ocurrió es que dict fue usado como origen para generar phones.dict, y solo se toma de él las palabras que aparecen en word-sorted.list. Es decir, sería totalmente posible tener un diccionario dict con muchas más traducciones palabra-fonemas como source. \r\n\r\nAdemás, debemos agregar al diccionario las siguientes lineas (manteniendo el orden alfabético)\r\n```\r\nSENT-END [] sil\r\nSENT-START [] sil\r\nSILENCE sil\r\n```\r\nQuedando finalmente: [Dictionary/phones.dict](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/phones.dict?at=master)\r\n\r\nLuego, debemos crear un nuevo archivo copiando Dictionary/phones-with-sp.list en el cual borremos la linea que contiene al fonema \"sp\", generando así el archivo [Dictionary/phones.list](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/phones.list?at=master)\r\n\r\n###2.2. Gramática a WordNet\r\nHTK utiliza un formato especial para representar la gramática, es un \"word network\" (red de palabras), básicamente, es una notación de bajo nivel llamada \"HTK Standard Lattice Format (SLF)\" en el cual, cada instancia de palabra y cada transición entre palabras esta listado explicitamente. Podemos crear esta red automaticamente utilizando el comando\r\n\r\n```\r\nHParse Dictionary/DictionarySources/grammar Dictionary/DictionarySources/grammar.wordnet \r\n```\r\nAclaración: Este comando es el único que no logré hacer funcionar en Mac OS X, así que opté por correrlo en Ubuntu donde no hubo problemas. \r\n\r\n###2.3. Master label files (mlf)\r\n\r\nA continuación crearemos una version \"naive\" de un master label file, y digo \"naive\" porque no explota el verdadero poder de estos archivos, que permiten, entre otras cosas, una organización más inteligente de labels y grabaciones de entrenamiento. \r\n\r\nPrimero, crearemos el archivo \"MFCCs words.mlf\"\r\n```\r\nirb Helpers/generate_mfccs_from_training.rb\r\n```\r\n\r\nEsto genera un archivo de la pinta\r\n\r\n```\r\n#!MLF!#\r\n\"*/train1-cero.lab\"\r\nCERO\r\n.\r\n\"*/train1-cinco.lab\"\r\nCINCO\r\n.\r\n\"*/train1-cuatro.lab\"\r\nCUATRO\r\n.\r\n\"*/train1-dos.lab\"\r\nDOS\r\n.\r\n\"*/train1-uno.lab\"\r\nUNO\r\n.\r\n\"*/train2-cero.lab\"\r\nCERO\r\n.\r\n\"*/train2-cinco.lab\"\r\nCINCO\r\n.\r\n\"*/train2-cuatro.lab\"\r\n...\r\n```\r\nNombre del archivo: [Data/train MFCCs-words.mlf](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/train MFCCs-words.mlf?at=master)\r\n\r\nLuego asegurarse que cada elemento contenga la transcripción a nivel palabras de lo que cada .wav contiene (el script lo hace en base al nombre del archivo). \r\n\r\nLuego debemos generar un archivo que contiene las transcripciones a nivel fonemas, para eso utilizaremos el comando `HLEd`\r\n\r\nPrimero, generaremos un archivo de configuración con la siguiente pinta:\r\n```\r\nEX\r\nIS sil sil\r\nDE sp\r\n\r\n```\r\nNombre del archivo: [Configs/HLEd.config](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Configs/HLEd.config?at=master)\r\n\r\nY luego, el comando propiamente dicho: \r\n```\r\nHLEd -l ’*’ -d Dictionary/phones.dict -i Data/train\\ MFCCs-phones.mlf Configs/HLEd.config Data/train\\ MFCCs-words.mlf\r\n```\r\nQue genera un archivo de la pinta:\r\n```\r\n#!MLF!#\r\n\"’*’/train1-cero.lab\"\r\nsil\r\ns\r\ne\r\nr\r\no\r\nsil\r\n.\r\n\"’*’/train1-cinco.lab\"\r\nsil\r\ns\r\ni\r\nn\r\nc\r\no\r\nsil\r\n.\r\n\"’*’/train1-cuatro.lab\"\r\nsil\r\nk\r\nu\r\na\r\nt\r\nr\r\no\r\nsil\r\n.\r\n...\r\n```\r\nNombre del archivo: [Data/train MFCCs-phones.mlf](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/train MFCCs-phones.mlf?at=master)\r\n\r\n\r\n###2.4. Mel Frequency Cepstral Coefficients (MFCCs)\r\nPara traducir los .wav al formato de features que utilizaremos (MFCCs), vamos a usar el comando *HCopy*\r\n\r\nPrimero, necesitamos generar ciertos archivos llamados *scripts* en el manual de HTK, que constan, generalmente, de listados de archivos que los comandos luego recorrerán y tomarán como input. \r\n\r\nPor ejemplo, antes de correr el comando HCopy, utilizaremos el siguiente comando\r\n```\r\nirb Helpers/generate_hcopy_script.rb\r\n```\r\n\r\nEste comando, crea un archivo de la pinta:\r\n```\r\n./Data/Recorded/waves/train/train1/cero.wav  ./Data/Train/train1-cero.mfc \r\n./Data/Recorded/waves/train/train1/cinco.wav  ./Data/Train/train1-cinco.mfc \r\n./Data/Recorded/waves/train/train1/cuatro.wav  ./Data/Train/train1-cuatro.mfc \r\n./Data/Recorded/waves/train/train1/dos.wav  ./Data/Train/train1-dos.mfc \r\n./Data/Recorded/waves/train/train1/nueve.wav  ./Data/Train/train1-nueve.mfc \r\n./Data/Recorded/waves/train/train1/ocho.wav  ./Data/Train/train1-ocho.mfc \r\n./Data/Recorded/waves/train/train1/seis.wav  ./Data/Train/train1-seis.mfc \r\n```\r\nNombre del archivo: [Scripts/HCopy.script](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Scripts/HCopy.script?at=master)\r\n\r\n\r\nLuego, necesitamos generar el archivo de configuración HCopy.config\r\n```\r\n# Coding parameters\r\nSOURCEKIND = WAVEFORM\r\nSOURCEFORMAT = WAV\r\nTARGETKIND = MFCC_0\r\nTARGETRATE = 100000.0\r\nSAVECOMPRESSED = T\r\nSAVEWITHCRC = T\r\nWINDOWSIZE = 250000.0\r\nUSEHAMMING = T\r\nPREEMCOEF = 0.97\r\nNUMCHANS = 26\r\nCEPLIFTER = 22\r\nNUMCEPS = 12\r\nENORMALISE = F\r\n\r\n```\r\nNombre del archivo: [Configs/HCopy.config](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Configs/HCopy.config?at=master)\r\n\r\nFinalmente, podemos correr HCopy para traducir de wavs a mfccs: \r\n```\r\nHCopy -T 1 -C Configs/HCopy.config -S Scripts/HCopy.script\r\n```\r\n\r\nSi todo salió bien, deberíamos tener la carpeta [Data/Train](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/Train?at=master) lleno de archivos .mfc (uno por cada grabación de entrenamiento)\r\n\r\n###2.5. Generación de un modelo prototípico\r\nPara lograr entrenar nuestro modelo, debemos partir de un modelo base que luego varíe hasta convertirse en el HMM final que utilizaremos para reconocer palabras. Este paso lo lograremos creando un modelo en Models/hmm0. \r\n\r\nLo primero que hay que hacer es crear un nuevo archivo que contenga lo siguiente:\r\n\r\n```\r\n  ~o <VecSize> 39 <MFCC_0_D_A>  \r\n  ~h \"prototype\"\r\n<BeginHMM>\r\n  <NumStates> 5\r\n  <State> 2 \r\n    <Mean> 39\r\n      0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \r\n    <Variance> 39\r\n      1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\r\n  <State> 3\r\n    <Mean> 39\r\n      0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \r\n    <Variance> 39\r\n      1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\r\n  <State> 4\r\n    <Mean> 39\r\n      0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \r\n    <Variance> 39\r\n      1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\r\n  <TransP> 5\r\n   0.000e+0   1.000e+0   0.000e+0   0.000e+0   0.000e+0\r\n   0.000e+0   6.000e-1   4.000e-1   0.000e+0   0.000e+0\r\n   0.000e+0   0.000e+0   6.000e-1   4.000e-1   0.000e+0\r\n   0.000e+0   0.000e+0   0.000e+0   6.000e-1   4.000e-1\r\n   0.000e+0   0.000e+0   0.000e+0   0.000e+0   0.000e+0\r\n<EndHMM>\r\n\r\n```\r\nNombre del archivo: [Models/prototype](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Models/prototype?at=master)\r\n\r\nLuego, necesitamos un archivo de configuración para el comando que utilizaremos:\r\n\r\n```\r\n# Coding parameters\r\nSOURCEFORMAT = HTK\r\nTARGETKIND = MFCC_0_D_A\r\nTARGETRATE = 100000.0\r\nSAVECOMPRESSED = T\r\nSAVEWITHCRC = T\r\nWINDOWSIZE = 250000.0\r\nUSEHAMMING = T\r\nPREEMCOEF = 0.97\r\nNUMCHANS = 26\r\nCEPLIFTER = 22\r\nNUMCEPS = 12\r\nENORMALISE = F\r\n\r\n```\r\nNombre del archivo: [Configs/HCompV.config](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Config/HCompV.config?at=master)\r\n\r\nY un listado correspondiente para este archivo\r\n\r\n```\r\nirb Helpers/generate_hcompv_script.rb\r\n```\r\n\r\nQue genera algo como: [Scripts/HCompV.script](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Scripts/HCompV.script?at=master)\r\n\r\nAhora si, podemos utilizar el comando para crear nuestro primer modelo entrenado a partir de los datos\r\n```\r\nHCompV -C Configs/HCompV.config -f 0.01 -m -S Scripts/HCompV.script -M Models/hmm0 Models/prototype\r\n```\r\n\r\nEsto genera 2 archivos [Models/hmm0/prototype](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Models/hmm0/prototype?at=master) y [Models/hmm0/vFloors](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Models/hmm0/vFloors?at=master) que nos serán utiles en el próximo paso.\r\n\r\n###2.6. Generación del primer modelo\r\nUna vez que tenemos los archivos [Models/hmm0/prototype](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Models/hmm0/prototype?at=master) y [Models/hmm0/vFloors](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Models/hmm0/vFloors?at=master), generaremos un nuevo archivo que contenga, una copia del prototipo por cada fonema utilizado (sin sp).\r\n\r\nEjemplo, el prototipo tiene la forma \r\n```\r\n  ~o <VecSize> 39 <MFCC_0_D_A>  \r\n  ~h \"prototype\"\r\n<BeginHMM>\r\n  <NumStates> 5\r\n  <State> 2 \r\n  ...\r\n<EndHMM>\r\n```\r\nDonde llamaré HMMPrototipo a lo que esta entre \\<BeginHMM\\> y \\<EndHMM\\> incluyendo estas etiquetas\r\n\r\nCrearemos otro archivo que contenga este modelo por cada fonema que encontremos en el archivo [Dictionary/phones.list](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/phones.list?at=master):\r\n\r\n```\r\n~h \"c\"\r\nHMMPrototipo\r\n~h \"e\"\r\nHMMPrototipo\r\n...\r\n```\r\nNombre del archivo: [Models/hmm0/hmmdefs](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Models/hmm0/hmmdefs?at=master)\r\n\r\nFinalmente, copiaremos el archivo Models/hmm0/vFloors a uno nuevo llamado macro agregando el siguiente header: \r\n\r\n```\r\n~o\r\n<STREAMINFO> 1 39\r\n<VECSIZE> 39<NULLD><MFCC_D_A_0><DIAGC>\r\n```\r\nNombre del archivo: [Models/hmm0/macros](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Models/hmm0/macros?at=master)\r\n\r\n##3. Entrenamiento del modelo\r\n\r\n###3.1. Hmm1 - Hmm3\r\nAhora si, ya tenemos un modelo prototípico del cual partir. Como hicimos anteriormente, generamos el listado necesario para el comando que utilizaremos, en este caso, HERest\r\n\r\n```\r\nirb Helpers/generate_herest_script.rb\r\n```\r\n\r\nAhora, re-estimaremos el modelo usando la herramienta para \"embedded re-estimation\" HERest\r\n\r\n```\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm0/macros -H Models/hmm0/hmmdefs -M Models/hmm1 Dictionary/phones.list\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm1/macros -H Models/hmm1/hmmdefs -M Models/hmm2 Dictionary/phones.list\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm2/macros -H Models/hmm2/hmmdefs -M Models/hmm3 Dictionary/phones.list\r\n```\r\n\r\n###3.2. Hmm4 - Hmm7\r\nEn este paso, debemos agregar el estado \"sp\" en una copia de hmmdefs de hmm3 y guardarlo en hmm4. Para agregar el estado, hacer lo siguiente:\r\n[agregar sp](http://www.voxforge.org/home/dev/acousticmodels/linux/create/htkjulius/tutorial/monophones/step-7)\r\n\r\nLuego del reemplazo, corremos:\r\n```\r\nHHEd -A -D -T 1 -H Models/hmm4/macros -H Models/hmm4/hmmdefs -M Models/hmm5 Configs/HHEd.config Dictionary/phones-with-sp.list\r\n```\r\n\r\nCuando se agrego el nuevo estado, seguimos re-estimando con:\r\n```\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm5/macros -H Models/hmm5/hmmdefs -M Models/hmm6 Dictionary/phones-with-sp.list\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm6/macros -H Models/hmm6/hmmdefs -M Models/hmm7 Dictionary/phones-with-sp.list\r\n```\r\n\r\n**Hasta aquí** llegará el entrenamiento, sin embargo, en el tutorial de HTK existen más pasos que permiten seguir entrenando el modelo para conseguir mejor performance. \r\n\r\n##4. Resultados\r\n\r\n###4.1. Grabar datos para testear\r\nDe la misma forma que grabamos los datos de entrenamiento (mismo formato sobre todo) grabaremos casos de prueba en la carpeta [Data/Recorded/waves/train], estos datos no necesitan transcripción, ya que esa será la salida de nuestro programa.\r\n\r\n###4.2. Generar vectores MFCC\r\nPrimero, debemos, al igual que con los datos de entrenamiento, listar los archivos de test que poseemos, por ejemplo\r\n```\r\n./Data/Recorded/waves/tests/0.wav ./Data/Test/0.mfc\r\n./Data/Recorded/waves/tests/1.wav ./Data/Test/1.mfc\r\n./Data/Recorded/waves/tests/2.wav ./Data/Test/2.mfc\r\n./Data/Recorded/waves/tests/3.wav ./Data/Test/3.mfc\r\n./Data/Recorded/waves/tests/4.wav ./Data/Test/4.mfc\r\n./Data/Recorded/waves/tests/5.wav ./Data/Test/5.mfc\r\n./Data/Recorded/waves/tests/6.wav ./Data/Test/6.mfc\r\n./Data/Recorded/waves/tests/7.wav ./Data/Test/7.mfc\r\n./Data/Recorded/waves/tests/8.wav ./Data/Test/8.mfc\r\n./Data/Recorded/waves/tests/9.wav ./Data/Test/9.mfc\r\n./Data/Recorded/waves/tests/12151516790.wav ./Data/Test/12151516790.mfc\r\n./Data/Recorded/waves/tests/64.wav ./Data/Test/64.mfc\r\n./Data/Recorded/waves/tests/111111111.wav ./Data/Test/111111111.mfc\r\n```\r\nNombre del archivo: [Scripts/HCopyTests.script](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Scripts/HCopyTests.script?at=master)\r\n\r\nLuego, generar el archivo de configuración:\r\n```\r\n# Coding parameters\r\nSOURCEKIND     = WAVEFORM\r\nSOURCEFORMAT = WAV\r\nTARGETKIND = MFCC_0_D_A\r\nTARGETRATE = 100000.0\r\nSAVECOMPRESSED = T\r\nSAVEWITHCRC = T\r\nWINDOWSIZE = 250000.0\r\nUSEHAMMING = T\r\nPREEMCOEF = 0.97\r\nNUMCHANS = 26\r\nCEPLIFTER = 22\r\nNUMCEPS = 12\r\nENORMALISE = F\r\n\r\n```\r\nNombre del archivo: [Configs/HCopyTests.config](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Configs/HCopyTests.config?at=master)\r\n\r\nY finalmente, los MFCCs a partir de los wavs:\r\n\r\n```\r\nHCopy -T 1 -C Configs/HCopyTests.config -S Scripts/HCopyTests.script\r\n```\r\n###4.3. Obtención de resultados\r\nPara testear contra el modelo entrenado, utilizaremos el comando `HVite`, para lo cual necesitamos el listado de archivos de entrenamiento:\r\n```\r\nirb Helpers/generate_hvite_script.rb \r\n```\r\n\r\nEste comando, crea un archivo de la pinta:\r\n```\r\n./Data/Test/0.mfc\r\n./Data/Test/1.mfc\r\n./Data/Test/111111111.mfc\r\n./Data/Test/12151516790.mfc\r\n...\r\n```\r\nNombre del archivo: [Scripts/HVite.script](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Scripts/HVite.script?at=master)\r\n\r\nY finalmente: \r\n```\r\nHVite -H Models/hmm7/macros -H Models/hmm7/hmmdefs -S Scripts/HVite.script -l ’*’ -i recout.mlf -w Dictionary/DictionarySources/grammar.wordnet -p 0.0 -s 5.0 Dictionary/phones.dict Dictionary/phones-with-sp.list\r\n```\r\n\r\nQue genera un archivo llamado [recout.mlf](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/recout.mlf?at=master) que contiene los resultados de las pruebas en formato MLF.\r\n\r\n###4.4. Obtener resultados en vivo\r\nTodavía no logré hacer funcionar el siguiente comando, pero se utilizar para no tener que grabar los tests sino hablarlos directamente y probar distintas combinaciones.\r\n```\r\nHVite -H Models/hmm7/macros -H Models/hmm7/hmmdefs -C Configs/Live.config -w Dictionary/DictionarySources/grammar.wordnet -p 0.0 -s 5.0 Dictionary/phones.dict Dictionary/phones-with-sp.list\r\n```\r\n\r\n## Preguntas? Comentarios?\r\nAnte cualquier duda o comentario, enviar un email a pbrusco@manas.com.ar o pablo.brusco@gmail.com\r\n\r\nGracias!","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}