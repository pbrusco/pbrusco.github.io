{"name":"Reconocimiento de Dígitos en Castellano utilizando HTK","tagline":"htk, dígitos, español, castellano, speech-recognition","body":"# Bienvenidos\r\nA continuación implementaremos un reconocedor de dígitos en español, más precisamente el español hablado en Argentina. Para ello utilizaremos HTK (una implementación de [Modelos Ocultos de Markov](http://es.wikipedia.org/wiki/Modelo_oculto_de_Márkov)) y seguiremos los pasos recomendados en el [manual de HTK](http://htk.eng.cam.ac.uk/docs/docs.shtml).\r\n\r\nLa idea de este tutorial es que contenga todas las herramientas necesarias para implementar **desde cero** un programa que reconozca los números del 0 al 9. \r\n\r\nPueden ver el código completo en este [repositorio.](https://bitbucket.org/pbrusco/tesis-proyectos/src/e393a5db8f242bb9b173f570fdd06554be5aa968/HTK/spike%20digitos?at=master)\r\n\r\n### Hacia dónde vamos?\r\nQueremos, a partir de grabaciones de entrada de la pinta:\r\n\r\n**Entrada**\r\n ![12151516790](https://dl.dropboxusercontent.com/u/43547597/Tutorial%20HTK/12151516790.png)\r\n                \r\nobtener la transcripción de los dígitos, por ejemplo\r\n\r\n**Salida**\r\n\"1 2 1 5 1 5 1 6 7 9 0\"\r\n\r\n##Preámbulos\r\nLa tarea de reconocimiento del habla (speech recognition) es una tarea difícil. La mayor dificultad está en la enorme cantidad de variaciones al analizar una palabra dicha por dos personas distintas, a través de dos canales distintos (estudio radial vs. teléfono), en situaciones distintas, con distintas emociones, por dos personas que hablan el mismo idioma pero de distintos orígenes, etc. E incluso, una misma persona intentando reproducir lo que dijo, nunca puede hacerlo exactamente igual. \r\n\r\nEsto implica, que la tarea de hacer que una maquina reconozca el habla incluye facilitarle datos de entrenamiento suficientes y buenos algoritmos para normalizar la señal acústica. \r\n\r\nUno de los métodos más utilizados en los últimos años están basados en \"Hidden Markov Models\" (HMMs), es decir, modelos probabilísticos sobre las señales acústicas que además, necesitan que esta señal esté expresada de alguna manera que permita comprarlas. Por lo tanto se combina esta técnica con otras como una que permite normalizar la señal acústica extrayendo los llamados \"Mel Frecuency Ceptral Coefficients\" (MFCCs) y luego, por ejemplo, utilizando \"Gaussian Mixture Models\" (GMMs), se consigue finalmente que se pueda comparar palabras habladas a pesar de sus variaciones esperables. \r\n\r\nExisten varios sistemas (o toolkits) que implementan y facilitan la interacción y entrenamiento de HMMs. En este tutorial utilizaremos [The Hidden Markov Model Toolkit (HTK)](http://htk.eng.cam.ac.uk). \r\n\r\n##Preparando el entorno\r\n\r\n###Software\r\nPara poder generar nuestro reconocedor, primero debemos descargar [HTK](http://htk.eng.cam.ac.uk/download.shtml). La forma de instalarlo depende de nuestro sistema operativo:\r\n\r\nDentro de la carpeta descargada: \r\n\r\n```\r\n ./configure\r\nmake all\r\nsudo make install\r\n```\r\n\r\n**HTK en Ubuntu**\r\n\r\nAnte algún problema, ejecutar:\r\n\r\n```\r\nsudo apt-get install gcc-multilib\r\nsudo apt-get install libx11-dev\r\n./configure --disable-hslab (por un error -lX11) \r\n```\r\n(si fue necesario realizar el ultimo paso, no dispondremos de la herramienta HSLab, reemplazable por, por ejemplo, audacity)\r\n\r\n**HTK en MAC (Mountain Lion)**\r\n\r\nAnte algún problema, asegurarse de tener instalado:\r\n\r\n* [XQuartz](http://xquartz.macosforge.org/landing/) (del cual necesitamos X11)\r\n* gcc, disponible con los [Command Line Tools](http://www.programadorfreelanceargentina.com/2012/05/como-instalar-xcode-command-line-tools.html) de XCode \r\n\r\nSi el problema persiste, agregar `-I/usr/X11R6/include` en los cflags de los makefiles que estan, en el directorio de htk y en htklib, (información sacada de esta [página] (http://aidiary.hatenablog.com/entry/20130113/1358046622), para leerla, traducir usando el traductor de google por ejemplo y tener cuidado que los comandos también se traducen). \r\n\r\n\r\n**Ruby**\r\n\r\nAdemás de HTK, recomiendo tener instalado [Ruby](http://www.ruby-lang.org/es/downloads/) (para ciertos scripts .rb) \r\n\r\n###Organización del código\r\nPara lograr hacer funcionar el programa, deberemos fijar la ubicación de cada uno de los archivos que creemos, recomiendo utilizar la misma estructura que yo utilizo ya que los comandos están preparados para estas rutas. Por supuesto, al ir entendiendo cada uno de los comandos y scripts, los archivos podrán ser movidos a donde el que los utilice considere.\r\n\r\n[Aquí](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/code_organization.txt?at=master) podrán encontrar una posible organización y es en la cual me basaré a partir de ahora. La idea no es intentar entenderla desde un principio, sino consultarla cuando se tiene alguna duda. \r\n\r\n###Sobre el formato de los archivos\r\nUna aclaración que puede ahorrarles horas de errores incomprensibles. En **TODOS** los archivos que se utilicen en los comandos de HTK, chequeen que siempre haya un \"enter\" al final (y que se encuentre en formato unix, opción disponible si usan [Sublime](http://www.sublimetext.com/): View/Line Endings/Unix por ejemplo)\r\n\r\n***\r\n# Implementación\r\n\r\n\r\n##1. Preparando los datos\r\n\r\n###1.1. Gramática\r\nPara que nuestro programa entienda palabras, lo primero que debemos indicarle es que forma pueden tener las oraciones que grabemos.\r\n\r\nDado que en nuestro caso queremos reconocer dígitos, lo haremos con la siguiente grámatica:\r\n```\r\n$digito = UNO | DOS | TRES | CUATRO | CINCO | SEIS | SIETE | OCHO | NUEVE | CERO;\r\n( SENT-START ( <$digito> ) SENT-END )\r\n```\r\nNombre del archivo: [Dictionary/DictionarySources/grammar](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/DictionarySources/grammar?at=master)\r\n\r\nMás info sobre el [lenguaje utilizado](http://www.ee.columbia.edu/ln/LabROSA/doc/HTKBook21/node131.html)\r\n\r\nBásicamente, se indica a través de este archivo, que las grabaciones tendrán dígitos (uno o más). \r\n\r\n###1.2. Listado de palabras\r\nEn este paso debemos listar todas las posibles palabras de nuestra gramática (ordenadas alfabeticamente). Para ello, podemos listarlas y luego aplicar el comando \"sort\" de unix. \r\n```\r\nCERO\r\nCINCO\r\nCUATRO\r\nDOS\r\nNUEVE\r\nOCHO\r\nSEIS\r\nSENT-END\r\nSENT-START\r\nSIETE\r\nTRES\r\nUNO\r\n```\r\nNombre del archivo: [Dictionary/DictionarySources/words-sorted.list](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/DictionarySources/words-sorted.list?at=master)\r\n\r\n###1.3. Diccionario de fonemas\r\nEste paso es importante e indica que fonemas utilizaremos para describir cada palabra, aquí es donde, el español hablado en España varía del hablado en Argentina, por ejemplo, la palabra \"cero\" puede tener las siguientes transcripciones a fonemas respectivamente.\r\n`CERO th e r o` o `CERO s e r o`\r\n\r\nYa que utilizaremos castellano, el diccionario tendrá la siguiente pinta:\r\n\r\n```\r\nCERO s e r o sp\r\nCINCO s i n c o sp\r\nCUATRO k u a t r o sp\r\nDOS d o s sp\r\nNUEVE n u e b e sp\r\nOCHO o ch o sp\r\nSEIS s e i s sp\r\nSENT-END sil\r\nSENT-START sil\r\nSIETE s i e t e sp\r\nTRES t r e s sp\r\nUNO u n o sp\r\n```\r\nNombre del archivo: [Dictionary/DictionarySources/dict](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/DictionarySources/dict?at=master)\r\n\r\n(notar que se agrega una pausa corta \"sp\" al final de cada palabra y que debe contenter SENT-START y SENT-END con \"sil\" para poder funcionar)\r\n\r\n###1.4. Grabando datos de entrenamiento\r\nPara poder entrenar nuestro sistema, se necesitan grabaciones de entrenamiento, la decisión sobre que datos de entrenamiento usar implican un mejor o peor desempeño en el reconocedor. Para esta prueba en particular, se grabaron 4 sets de entrenamiento (train1, train2, train3 y train4) en dónde cada uno contiene una grabación por cada dígito (de manera aislada, es decir, solo el dígito de comienzo a fin sin silencios) \r\n\r\nEjemplo: [Data/Recorded/waves/train/train1/seis.wav](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/Recorded/waves/train/train1/seis.wav?at=master)\r\n\r\nPor otro lado, cada uno de estos datos de entrenamiento necesitan una transcripción (.lab), esta transcripción debe contener los fonemas que se utilizan en la palabra grabada. \r\n\r\nEn vez de hacerlo manualmente, aprovecharemos un script que se encargará de facilitarnos ese trabajo, pero en caso de no tener este script, habría que construirlos manualmente con la pinta:\r\n\r\n```\r\n0.0 0.5064375  o ch o\r\n```\r\nNombre del archivo: [Data/Train/train1-ocho.lab](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Data/Train/train1-ocho.lab?at=master)\r\n\r\nEl script que utilizaremos es [Helpers/labels_from_wavs_script.rb](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Helpers/labels_from_wavs_script.rb?at=master)\r\n\r\n```\r\nsudo gem install waveinfo\r\nirb Helpers/labels_from_wavs_script.rb \"Data/Recorded/waves/train/\" \"Data/Train/\"\r\n```\r\n\r\nEste scipt escanea Data/Recorded/waves/train en búsqueda de subcarpetas que contengan wavs. Al encontrarlos, genera un archivo .lab por cada .wav y los guarda en el la carpeta del segundo parametro \"Data/Train/\" con el nombre \"subcarpeta\"-\"nombre\".lab (ejemplo el archivo train1-8.lab mostrado anteriormente)\r\n\r\n\r\n\r\n\r\n##2. Combinando los datos\r\n\r\n###2.1. Diccionario y listado de fonemas\r\n\r\nPara generar el diccionario y listado de fonemas que utilizaremos más adelante, usaremos el comando HDMan de HTK: \r\n\r\n```\r\nHDMan -m -w Dictionary/DictionarySources/words-sorted.list -n Dictionary/phones-with-sp.list -l dlog Dictionary/phones.dict Dictionary/DictionarySources/dict\r\n```\r\n\r\nEsto último, genera 2 archivos importantes: [Dictionary/phones.dict](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/phones.dict?at=master) y [Dictionary/phones-with-sp.list](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/phones-with-sp.list?at=master), y por otro lado, un log (dlog) que sirve para ver cuantas repeticiones de los fonemas se utilizan. \r\n\r\nPodrán notar que phones.dict y DictionarySources/dict son muy parecidos (o iguales en este caso), la razón para que esto ocurra es que dict es usado como source para generar phones.dict, y solo se toma de él las palabras que aparecen en word-sorted.list. Es decir, sería totalmente posible tener un diccionario dict con muchas más traducciones palabra-fonemas como source. \r\n\r\nLuego, debemos crear un nuevo archivo copiando Dictionary/phones-with-sp.list en el cual borremos la linea que contiene al fonema \"sp\", generando así el archivo [Dictionary/phones.list](https://bitbucket.org/pbrusco/tesis-proyectos/src/master/HTK/spike%20digitos/Dictionary/phones.list?at=master)\r\n\r\n###2.2. Gramática a WordNet\r\nHTK utiliza un formato especial para representar la gramática, es un \"word network\" (red de palabras), básicamente, es una notación de bajo nivel llamada \"HTK Standard Lattice Format (SLF)\" en el cual, cada instancia de palabra y cada transición entre palabras esta listado explicitamente. Podemos crear esta red automaticamente utilizando el comando\r\n\r\n```\r\nHParse Dictionary/DictionarySources/grammar Dictionary/DictionarySources/grammar.wordnet \r\n```\r\nAclaración: Este comando es el único que no logré hacer funcionar en Mac OS X, así que opté por correrlo en Ubuntu donde no hubo problemas. \r\n\r\n###2.3. Master label files (mlf)\r\n\r\n\r\nCrear \"MFCCs words.mlf\"\r\n```\r\nirb Helpers/generate_mfccs_from_training.rb\r\n```\r\n\r\nLuego modificar cada elemento para que contenga la transcripción a nivel palabras de lo que cada .wav contiene.\r\n\r\n\r\nLuego debemos generar un archivo que contiene las transcripciones a nivel fonemas, para eso utilizaremos el comando: \r\n\r\n```\r\nHLEd -l ’*’ -d Dictionary/phones.dict -i Data/train\\ MFCCs-phones.mlf Configs/HLEd.config Data/train\\ MFCCs-words.mlf\r\n```\r\n\r\n### Listado de archivos de entrenamiento para HCopy\r\n\r\nPara generar HCopy.script \r\n```\r\nirb Helpers/generate_hcopy_script.rb\r\n```\r\n\r\n### Mel Frequency Cepstral Coefficients\r\nPara generar MFCCs a partir de wavs, primero necesitamos generar el archivo de configuración HCopy.config\r\n```\r\nHCopy.config\r\n```\r\n\r\nLuego\r\n```\r\nHCopy -T 1 -C Configs/HCopy.config -S Scripts/HCopy.script\r\n```\r\n\r\n###2.4. Preparando la estructura para el modelo\r\n\r\n\r\nAhora necesitamos crear una serie de carpetas para poder almacenar los modelos, podemos usar el siguiente comando Bash:\r\n\r\n```\r\nfor NUMBER in {0..9}\r\ndo\r\n  mkdir Models/hmm$NUMBER\r\ndone\r\n```\r\n\r\n###2.5. Listado de archivos de entrenamiento para HCompV\r\n\r\n\r\nPara generar HCompV.script:\r\n```\r\nirb Helpers/generate_hcompv_script.rb\r\n```\r\n\r\n\r\n##3. Entrenamiento del modelo\r\n\r\n###3.1. Hmm0 - Hmm3\r\nPrimer modelo prototípico:\r\n```\r\n  ~o <VecSize> 39 <MFCC_0_D_A>  \r\n  ~h \"prototype\"\r\n<BeginHMM>\r\n  <NumStates> 5\r\n  <State> 2 \r\n    <Mean> 39\r\n      0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \r\n    <Variance> 39\r\n      1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\r\n  <State> 3\r\n    <Mean> 39\r\n      0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \r\n    <Variance> 39\r\n      1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\r\n  <State> 4\r\n    <Mean> 39\r\n      0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \r\n    <Variance> 39\r\n      1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\r\n  <TransP> 5\r\n   0.000e+0   1.000e+0   0.000e+0   0.000e+0   0.000e+0\r\n   0.000e+0   6.000e-1   4.000e-1   0.000e+0   0.000e+0\r\n   0.000e+0   0.000e+0   6.000e-1   4.000e-1   0.000e+0\r\n   0.000e+0   0.000e+0   0.000e+0   6.000e-1   4.000e-1\r\n   0.000e+0   0.000e+0   0.000e+0   0.000e+0   0.000e+0\r\n<EndHMM>\r\n\r\n```\r\n\r\nPrimer paso, modelo prototípico a la carpeta hmm0\r\n\r\nNuevamente necesitamos el archivo de configuración correspondiente:\r\n```\r\nHCompV.config\r\n```\r\n\r\nAhora si, \r\n```\r\nHCompV -C Configs/HCompV.config -f 0.01 -m -S Scripts/HCompV.script -M Models/hmm0 Models/prototype\r\n```\r\n\r\n* Copiar el prototipo en hmmdefs (uno por cada fonema, utilizando phones.list)\r\n* Copiar vFloors a macros agregando el header\r\n\r\nGenerar el script para HERest\r\n```\r\nirb Helpers/generate_herest_script.rb\r\n```\r\n\r\nRe-estimar usando la herramienta para \"embedded re-estimation\" HERest\r\n\r\n```\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm0/macros -H Models/hmm0/hmmdefs -M Models/hmm1 Dictionary/phones.list\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm1/macros -H Models/hmm1/hmmdefs -M Models/hmm2 Dictionary/phones.list\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm2/macros -H Models/hmm2/hmmdefs -M Models/hmm3 Dictionary/phones.list\r\n```\r\n\r\n###3.2. Hmm4 - Hmm7\r\nAgregar el estado \"sp\" en una copia de hmmdefs de hmm3 y guardarlo en hmm4. Para agregar el estado, hacer lo siguiente:\r\n[agregar sp](http://www.voxforge.org/home/dev/acousticmodels/linux/create/htkjulius/tutorial/monophones/step-7)\r\n\r\n```\r\nHHEd -A -D -T 1 -H Models/hmm4/macros -H Models/hmm4/hmmdefs -M Models/hmm5 Configs/HHEd.config Dictionary/phones-with-sp.list\r\n```\r\n```\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm5/macros -H Models/hmm5/hmmdefs -M Models/hmm6 Dictionary/phones-with-sp.list\r\nHERest -T 1 -C Configs/HERest.config -I Data/train\\ MFCCs-phones.mlf -t 1000.0 1000.0 10000.0 -S Scripts/HERest.script -H Models/hmm6/macros -H Models/hmm6/hmmdefs -M Models/hmm7 Dictionary/phones-with-sp.list\r\n```\r\n\r\n\r\n\r\n##4. Resultados\r\n\r\n###4.1. Grabar datos para testear\r\n###4.2. Generar vectores MFCC\r\n \r\nGenerar los MFCCs de los datos de testeo\r\n```\r\nHCopy -T 1 -C Configs/HCopyTests.config -S Scripts/HCopyTests.script\r\n```\r\n### Obtener resultados\r\nResultados: \r\n```\r\nHVite -H Models/hmm7/macros -H Models/hmm7/hmmdefs -S Scripts/HVite.script -l ’*’ -i recout.mlf -w Dictionary/DictionarySources/grammar.wordnet -p 0.0 -s 5.0 Dictionary/phones.dict Dictionary/phones-with-sp.list\r\n```\r\n\r\n###4.3. Obtener resultados en vivo\r\nResultados en vivo:\r\n```\r\nHVite -H Models/hmm7/macros -H Models/hmm7/hmmdefs -C Configs/Live.config -w Dictionary/DictionarySources/grammar.wordnet -p 0.0 -s 5.0 Dictionary/phones.dict Dictionary/phones-with-sp.list\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}